{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[0;32m     59\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, num_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m lr\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(X_train), y_train)\n\u001b[0;32m     61\u001b[0m predictions \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(X_eval\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Confusion matrix\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 33\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "os.chdir('C:/Users/asus/Documents/GitHub/CMSC-197-Miniproject')\n",
    "\n",
    "# Read JSON file\n",
    "df = pd.read_json('data/amazon_data.json', orient='records')\n",
    "\n",
    "# Assign X and y\n",
    "X = df['Review_Text']\n",
    "y = df['Label']\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Training and test set\n",
    "train_size = 0.8\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=None)\n",
    "\n",
    "# Convert labels to binary\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Create logistic regression model\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.m, self.n = X.shape\n",
    "        self.weights = np.zeros(self.n)\n",
    "        self.bias = 0\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            self.update_weights()\n",
    "\n",
    "    def update_weights(self):\n",
    "        linear_model = self.X.dot(self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "\n",
    "        dw = (1 / self.m) * np.dot(self.X.T, (y_predicted - self.y))\n",
    "        db = (1 / self.m) * np.sum(y_predicted - self.y)\n",
    "\n",
    "        self.weights -= self.learning_rate * dw\n",
    "        self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = X.dot(self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return np.array(y_predicted_cls)\n",
    "\n",
    "# Test the model\n",
    "lr = LogisticRegression(learning_rate=0.8, num_iterations=10000)\n",
    "lr.fit(np.array(X_train), y_train)\n",
    "predictions = lr.predict(X_eval.toarray())\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "cv_scores = cross_val_score(lr, X, y, cv=10)\n",
    "\n",
    "print(f\"10-fold Cross Validation Accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
